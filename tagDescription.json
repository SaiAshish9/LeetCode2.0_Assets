{
  "biconnected_component": [
    "Biconnected components in a network are essentially the edges that, if removed, would disconnect the network. These are crucial for maintaining connectivity within the network.",
    "The problem typically involves representing a network as a graph, where nodes represent entities (such as computers or routers) and edges represent connections between these entities. The task is to find all the critical connections in the network, i.e., the edges whose removal would increase the number of connected components in the graph.",
    "One common approach to solving this problem is by using Tarjan's algorithm for finding articulation points and bridges in an undirected graph. In this algorithm, you perform a depth-first search (DFS) on the graph, keeping track of certain properties of the nodes and edges encountered during the traversal.",
    "Here's a high-level overview of the algorithm:",
    "1. Perform a DFS traversal of the graph, starting from any node\n2. During the traversal, maintain a timestamp for each node indicating when it was visited.\n3. Keep track of the lowest timestamp reachable from each node in the DFS traversal, which helps in identifying back edges.\n4. If you encounter a back edge (an edge to an ancestor in the DFS tree), update the lowest reachable timestamp for the corresponding node.\n5. If the lowest reachable timestamp of a child node is greater than or equal to the timestamp of the current node, then the edge connecting them is a critical connection.",
    "By applying Tarjan's algorithm, you can identify all the critical connections in the network efficiently. This algorithm typically runs in linear time complexity relative to the size of the graph.",
    "Once you've identified the critical connections, you can return them as a list of edges."
  ],
  "rejection_sampling": [
    "Rejection Sampling typically involves generating random samples that meet specific criteria or fit a desired distribution.",
    "LeetCode Problem: Implement Rand10() Using Rand7() (LeetCode 470)",
    "Problem Statement:",
    "You have a function rand7() that generates a random integer from 1 to 7. You need to write a function rand10() that generates a random integer from 1 to 10 uniformly using rand7().",
    "Rejection Sampling Approach:",
    "The key idea behind using rejection sampling for this problem is to transform the output of rand7() to achieve a uniform distribution over a different range (1 to 10) by generating a larger set of candidate numbers and then rejecting those that do not fit the desired criteria.",
    "Here's a step-by-step explanation of how rejection sampling can be applied to this problem:",
    "Generate a Candidate from rand7():",
    "1. Use rand7() twice to generate a number in the range 1 to 49. This can be done by interpreting the results of two rand7() calls as digits in a base-7 number.\n2. Specifically, compute the candidate number as (rand7() - 1) * 7 + rand7(). This generates a uniform integer in the range 1 to 49 because rand7() produces each number 1 through 7 with equal probability.",
    "Reject or Accept the Candidate:",
    "1. Since 49 is not a multiple of 10, not all numbers from 1 to 49 map evenly to the range 1 to 10. To maintain uniformity, we only accept numbers in the range 1 to 40 because 40 is the largest multiple of 10 less than 49.\n2. If the generated number falls within this range (1 to 40), we map it to the range 1 to 10 using modulo operation and return the result.\n3. If the number is outside this range (41 to 49), we reject it and repeat the process.",
    "Implementation in Python:",
    "Hereâ€™s how the rejection sampling algorithm can be implemented:",
    "import random",
    "def rand7():\n\treturn random.randint(1, 7)",
    "def rand10():\n\twhile True:\n\t\tnum = (rand7() - 1) * 7 + rand7()  # Generate a number in the range 1 to 49\n\t\tif num <= 40:  # Accept only if the number is in the range 1 to 40\n\t\t\treturn 1 + (num - 1) % 10  # Map to range 1 to 10",
    "print([rand10() for _ in range(10)])",
    "Detailed Explanation:",
    "Generate Candidate: (rand7() - 1) * 7 + rand7() produces a number from 1 to 49 because rand7() generates a number from 1 to 7, and multiplying by 7 shifts the range accordingly.",
    "Acceptance Condition: if num <= 40 ensures we only consider numbers that can be mapped uniformly to 1 to 10.",
    "Mapping: 1 + (num - 1) % 10 converts the accepted number to the desired range 1 to 10.",
    "By only accepting numbers from 1 to 40, we ensure that each number from 1 to 10 can be mapped equally using modulo operation. Numbers 41 to 49 are rejected to avoid bias.",
    "This example illustrates how rejection sampling can be used to transform a random number generator into a uniform random generator over a different range. The key steps are generating a candidate, checking if it falls within the acceptable range, and rejecting or accepting it based on that criterion. This ensures that the resulting distribution is uniform and meets the problem requirements."
  ],
  "radix_sort": [
    "For input list with negative integers, please refer to the 912. Sort an Array question",
    "Radix sort is a non-comparative integer sorting algorithm that sorts data with integer keys by processing individual digits. It is particularly effective when the range of possible key values is not too large and is well-suited for sorting large lists of integers. Radix sort can be performed using either the least significant digit (LSD) or the most significant digit (MSD) method.\n\nHere's an overview of both methods:\n\nRadix sort can be a suitable choice for problems involving sorting large lists of integers or strings where the maximum value or length is not excessively large.\n\nLSD Radix Sort (Least Significant Digit)\n\n1. Initialize:\n   - Start with the least significant digit (rightmost).\n   \n2. Sorting:\n   - Group the numbers based on the current digit being considered.\n   - Sort the numbers within each group.\n\n3. Repeat:\n   - Move to the next significant digit to the left and repeat the process.\n   - Continue until the most significant digit is processed.\n\nMSD Radix Sort (Most Significant Digit)\n\n1. Initialize:\n   - Start with the most significant digit (leftmost).\n\n2. Sorting:\n   - Group the numbers based on the current digit being considered.\n   - Sort the numbers within each group.\n\n3. Recursion:\n   - Recursively sort the groups using the next significant digit to the right.\n   - Continue the process until the least significant digit is processed.\n\nExample of LSD Radix Sort\n\nConsider sorting the following list of integers:\n\n\n[170, 45, 75, 90, 802, 24, 2, 66]\n\n\nStep-by-Step Process\n\n1. Sort by the least significant digit (units place):\n\n   \n   [170, 90, 802, 2, 24, 45, 75, 66]\n   \n\n2. Sort by the next significant digit (tens place):\n\n   \n   [802, 2, 24, 45, 66, 170, 75, 90]\n   \n\n3. Sort by the most significant digit (hundreds place):\n\n   \n   [2, 24, 45, 66, 75, 90, 170, 802]\n   \n\nThe list is now sorted.\n\nAdvantages of Radix Sort\n\n- Efficiency: Radix sort can be faster than comparison-based sorting algorithms (like quicksort, mergesort) when the range of the keys (digits) is not too large.\n- Simplicity: The algorithm is simple and can be implemented easily for integer keys.\n- Stability: Radix sort is stable, meaning that it preserves the relative order of records with equal keys.\n\nDisadvantages of Radix Sort\n\n- Memory Usage: Radix sort requires additional memory for temporary storage during sorting.\n- Limited Applicability: Radix sort is not suitable for all types of data, particularly for floating-point numbers or strings with varying lengths.\n\nImplementation in Java\n\nHere's a Java implementation of LSD radix sort:\n\njava\nimport java.util.Arrays;\n\npublic class RadixSort {\n\n    public static void radixSort(int[] arr) {\n        int max = Arrays.stream(arr).max().getAsInt();\n        int exp = 1;\n        while (max / exp > 0) {\n            countingSort(arr, exp);\n            exp *= 10;\n        }\n    }\n\n    private static void countingSort(int[] arr, int exp) {\n        int n = arr.length;\n        int[] output = new int[n];\n        int[] count = new int[10];\n        \n        // Store the count of occurrences in count[]\n        for (int i = 0; i < n; i++) {\n            int index = (arr[i] / exp) % 10;\n            count[index]++;\n        }\n        \n        // Change count[i] so that it contains the actual position of this digit in output[], We transform this array so that each entry at index i contains the cumulative sum of counts up to i. This tells us the position where each digit should be placed in the output array. \n        for (int i = 1; i < 10; i++) {\n            count[i] += count[i - 1];\n        }\n        \n        // Build the output array\n        for (int i = n - 1; i >= 0; i--) {\n            int index = (arr[i] / exp) % 10;\n            output[count[index] - 1] = arr[i];\n            count[index]--;\n        }\n        \n        // Copy the output array to arr[], so that arr now contains sorted numbers according to the current digit\n        System.arraycopy(output, 0, arr, 0, n);\n    }\n\n    public static void main(String[] args) {\n        int[] arr = {170, 45, 75, 90, 802, 24, 2, 66};\n        radixSort(arr);\n        System.out.println(Arrays.toString(arr)); // Output: [2, 24, 45, 66, 75, 90, 170, 802]\n    }\n}\n\n\nExplanation\n\n1. Counting Sort Function:\n   - A helper function that sorts elements based on the current digit (specified by `exp`).\n\n2. Radix Sort Function:\n   - It repeatedly calls the counting sort for each digit, starting from the least significant digit to the most significant digit.\n   - `exp` is used to isolate each digit.\n\nRadix sort can be very efficient for specific types of data, especially when the number of digits (d) and the range of digits (k) are relatively small. It avoids the (O(n log n)) lower bound of comparison-based sorting algorithms, making it useful in certain scenarios.\n\nTime and Space Complexities\n\nTime Complexity:\n- Average Case: (O(d. (n + k)))\n- Worst Case: (O(d. (n + k)))\n  - Where (d) is the number of digits in the largest number (or length of the longest string), (n) is the number of elements, and (k) is the range of the digits (e.g., 0-9 for decimal numbers).\n\nSpace Complexity:\n- Auxiliary Space: (O(n + k))\n  - Additional space is used to create buckets for grouping digits or characters. The space complexity depends on the number of elements (n) and the range of digits (k).\n",
    "Time Complexity of Radix Sort\n\nThe time complexity of Radix Sort is determined by the following factors:\n- (d): The number of digits in the largest number (or the length of the longest string if sorting strings).\n- (n): The number of elements in the input array.\n- (k): The range of the digits (for decimal numbers, (k) is 10, since digits range from 0 to 9).\n\nThe overall time complexity is given by (O(d (n + k))).\n\n#Breaking it Down:\n1. Counting Sort Complexity: \n   - Counting Sort is used as a subroutine within Radix Sort.\n   - The time complexity of Counting Sort is (O(n + k)).\n\n2. Number of Passes (d):\n   - Radix Sort performs Counting Sort for each digit. If the maximum number in the array has (d) digits, then there will be (d) passes.\n   - Therefore, the total time complexity of Radix Sort is (O(d (n + k))).\n\nAnalysis:\n1. Average Case: (O(d (n + k)))\n   - This is the expected performance in general situations.\n\n2. Worst Case: (O(d (n + k)))\n   - This is also the performance in the worst-case scenario since Radix Sort does not have a different behavior for worst-case inputs as some other sorting algorithms might.\n\nComparing with Other Complexities:\n- Linear Time Complexity: (O(n))\n  - Radix Sort can achieve linear time complexity if (d) and (k) are constant values or do not grow with (n). For example, if all numbers have a fixed number of digits and the digit range is fixed.\n  \n- Quadratic Time Complexity: (O(n^2))\n  - Radix Sort does not reach (O(n^2)) time complexity unless (d) and (k) are very large in relation to (n), which is uncommon in practical scenarios. In typical uses, (d) and (k) are much smaller compared to (n), leading to a more efficient sort than (O(n^2)).\n\nBest Time Complexity:\nThe best time complexity of Radix Sort is (O(n)). This occurs under the following conditions:\n- (d) (number of digits) is a small constant.\n- (k) (range of digits) is also a small constant.\n\nIn such cases, the overall time complexity simplifies to (O(n)), since (d) and (k) do not grow with (n).\n\nSummary:\n- Average Case Time Complexity: (O(d (n + k)))\n- Worst Case Time Complexity: (O(d (n + k)))\n- Best Case Time Complexity: (O(n)) (when (d) and (k) are constants)\n\nRadix Sort is very efficient when the number of digits (d) and the range (k) are relatively small compared to the number of elements (n). It provides a linear time sorting alternative in such scenarios, outperforming typical comparison-based sorts like Quick Sort and Merge Sort which have (O(n log n)) time complexity."
  ],
  "eulerian_circuit": [
    "An Eulerian Circuit in a graph is a circuit that visits every edge exactly once and returns to the starting vertex. The necessary conditions for an Eulerian Circuit are:\n\n1. For undirected graphs: Every vertex must have an even degree, and all vertices with non-zero degree must be connected.\n2. For directed graphs: Every vertex must have equal in-degree and out-degree, and all vertices with non-zero degree must be strongly connected.\n\nHierholzerâ€™s algorithm is used to find an Eulerian path or circuit in a graph. In this problem, we adapt the algorithm to find an Eulerian path in a directed graph, where we must visit every edge (flight) exactly once. The algorithm involves traversing the graph and backtracking as necessary to cover all edges.\n\nA De Bruijn graph is a directed graph that represents overlapping subsequences of symbols from a larger sequence. It has applications in various fields, including computer science, bioinformatics, and cryptography.\n\nConsider a De Bruijn graph ðµ ( 2 , 3 ) B(2,3) over the binary alphabet {(0, 1)} {(0, 1)}. It consists of vertices representing all possible 3-bit binary sequences: 000, 001, 010, 011, 100, 101, 110, and 111. The edges are determined by the overlapping subsequences of length ð‘› âˆ’ 1 = 2.\n\nFor example, there is an edge from 001 to 010 because the last 2 bits of 001 match the first 2 bits of 010. Similarly, there is an edge from 110 to 101 because the last 2 bits of 110 match the first 2 bits of 101.\n\nJava Implementation Using Hierholzerâ€™s Algorithm\n\nExample\nHere is an example of how Hierholzerâ€™s algorithm works in a graph with an Eulerian circuit.\n\nGiven graph:\n\n    A - B\n    |     |\n    D - C\nAdjacency List:\n\nA: B, D\nB: A, C\nC: B, D\nD: A, C\n\nSteps:\n\nStart at vertex A.\nFollow an edge from A to B, removing the edge A-B.\nFollow an edge from B to C, removing the edge B-C.\nFollow an edge from C to D, removing the edge C-D.\nFollow an edge from D to A, removing the edge D-A.\nSince A has no more edges, backtrack, appending A to the path.\nContinue backtracking and appending each vertex to the path until the stack is empty.\nFinal Eulerian circuit path: A -> B -> C -> D -> A\n\nHereâ€™s how you can implement the solution in Java:\n\nGraph Representation: Use an adjacency list.\nDegree Calculation: Track in-degrees and out-degrees.\nCondition Checking: Ensure each vertex has equal in-degree and out-degree.\n\nHierholzerâ€™s Algorithm: To find the Eulerian Circuit.\n\nimport java.util.*;\n\npublic class EulerianCircuit {\n\n    // Function to perform Hierholzer's Algorithm\n    public static List<Integer> hierholzer(Map<Integer, LinkedList<Integer>> graph, int startNode) {\n        Stack<Integer> stack = new Stack<>();\n        List<Integer> circuit = new ArrayList<>();\n        stack.push(startNode);\n\n        while (!stack.isEmpty()) {\n            int u = stack.peek();\n            if (graph.get(u).size() > 0) {\n                int v = graph.get(u).removeFirst();\n                stack.push(v);\n            } else {\n                circuit.add(stack.pop());\n            }\n        }\n        Collections.reverse(circuit);\n        return circuit;\n    }\n\n    public static List<Integer> findEulerianCircuit(List<int[]> edges) {\n        Map<Integer, LinkedList<Integer>> adjList = new HashMap<>();\n        Map<Integer, Integer> inDegree = new HashMap<>();\n        Map<Integer, Integer> outDegree = new HashMap<>();\n\n        // Step 1: Build the graph from the edge list\n        for (int[] edge : edges) {\n            int u = edge[0], v = edge[1];\n            adjList.putIfAbsent(u, new LinkedList<>());\n            adjList.putIfAbsent(v, new LinkedList<>());\n            adjList.get(u).add(v);\n            outDegree.put(u, outDegree.getOrDefault(u, 0) + 1);\n            inDegree.put(v, inDegree.getOrDefault(v, 0) + 1);\n        }\n\n        // Step 2: Check the necessary conditions for an Eulerian Circuit\n        Integer startNode = null;\n        for (int node : adjList.keySet()) {\n            if (!outDegree.getOrDefault(node, 0).equals(inDegree.getOrDefault(node, 0))) {\n                return Collections.emptyList(); // No Eulerian Circuit exists\n            }\n            if (startNode == null) {\n                startNode = node;\n            }\n        }\n\n        // Step 3: Find Eulerian Circuit using Hierholzer's Algorithm\n        if (startNode == null) return Collections.emptyList();\n        return hierholzer(adjList, startNode);\n    }\n\n    public static void main(String[] args) {\n        List<int[]> edges = Arrays.asList(\n            new int[]{0, 1},\n            new int[]{1, 2},\n            new int[]{2, 0}\n        );\n\n        List<Integer> eulerianCircuit = findEulerianCircuit(edges);\n        System.out.println(eulerianCircuit);\n    }\n}\n\n\nExplanation\n\nGraph Representation:\n\nThe graph is represented using a Map<Integer, LinkedList<Integer>> where each key is a node, and the value is a list of nodes it is connected to.\ninDegree and outDegree maps keep track of the in-degree and out-degree of each node.\n\nBuilding the Graph:\n\nFor each edge (u, v), update the adjacency list, out-degree of u, and in-degree of v.\n\nChecking Conditions:\n\nEnsure each vertex has equal in-degree and out-degree. If any vertex fails this condition, an Eulerian Circuit does not exist.\nIdentify a start node for the algorithm.\n\nHierholzerâ€™s Algorithm:\n\nUse a stack to traverse the graph starting from the identified start node. Remove edges as they are traversed to avoid revisiting them.\nWhen you cannot continue from a node, backtrack and add the node to the circuit list.\nFinally, reverse the circuit list to get the correct order of traversal.\n\nMain Method:\n\nDemonstrates calling findEulerianCircuit with a sample edge list and prints the resulting Eulerian Circuit.\n"
  ],
  "strongly_connected component": [
    "In graph theory, a strongly connected component (SCC) of a directed graph is a maximal strongly connected subgraph. That is, a subgraph where there is a path from each vertex to every other vertex within the subgraph. SCCs are significant in various applications like understanding the structure of networks, optimizing compilers, and analyzing social networks.\n\nKosaraju's Algorithm in Java\n\nKosaraju's Algorithm consists of two main phases. Here is a detailed implementation in Java:\n\nimport java.util.*;\n    \npublic class KosarajuSCC {\n        \n        // First DFS to fill stack according to finishing times\n        private void fillOrder(int v, boolean[] visited, Stack<Integer> stack, List<List<Integer>> adj) {\n            visited[v] = true;\n            for (int neighbor : adj.get(v)) {\n                if (!visited[neighbor]) {\n                    fillOrder(neighbor, visited, stack, adj);\n                }\n            }\n            stack.push(v);\n        }\n    \n        // Transpose the graph\n        private List<List<Integer>> getTranspose(List<List<Integer>> adj, int V) {\n            List<List<Integer>> transpose = new ArrayList<>();\n            for (int i = 0; i < V; i++) {\n                transpose.add(new ArrayList<>());\n            }\n            for (int v = 0; v < V; v++) {\n                for (int neighbor : adj.get(v)) {\n                    transpose.get(neighbor).add(v);\n                }\n            }\n            return transpose;\n        }\n    \n        // DFS for the transposed graph\n        private void DFSUtil(int v, boolean[] visited, List<List<Integer>> adj, List<Integer> component) {\n            visited[v] = true;\n            component.add(v);\n            for (int neighbor : adj.get(v)) {\n                if (!visited[neighbor]) {\n                    DFSUtil(neighbor, visited, adj, component);\n                }\n            }\n        }\n    \n        // Function to find and print all SCCs\n        public List<List<Integer>> stronglyConnectedComponents(int V, List<List<Integer>> adj) {\n            Stack<Integer> stack = new Stack<>();\n            boolean[] visited = new boolean[V];\n    \n            // Fill vertices in stack according to their finishing times\n            for (int i = 0; i < V; i++) {\n                if (!visited[i]) {\n                    fillOrder(i, visited, stack, adj);\n                }\n            }\n    \n            // Create a transposed graph\n            List<List<Integer>> transpose = getTranspose(adj, V);\n    \n            // Mark all vertices as not visited (for second DFS)\n            Arrays.fill(visited, false);\n            List<List<Integer>> sccs = new ArrayList<>();\n    \n            // Process all vertices in order defined by Stack\n            while (!stack.isEmpty()) {\n                int v = stack.pop();\n                if (!visited[v]) {\n                    List<Integer> component = new ArrayList<>();\n                    DFSUtil(v, visited, transpose, component);\n                    sccs.add(component);\n                }\n            }\n            return sccs;\n        }\n    \n        public static void main(String[] args) {\n            KosarajuSCC kosaraju = new KosarajuSCC();\n            int V = 5;\n            List<List<Integer>> adj = new ArrayList<>();\n            for (int i = 0; i < V; i++) {\n                adj.add(new ArrayList<>());\n            }\n    \n            adj.get(0).add(2);\n            adj.get(2).add(1);\n            adj.get(1).add(0);\n            adj.get(0).add(3);\n            adj.get(3).add(4);\n    \n            List<List<Integer>> sccs = kosaraju.stronglyConnectedComponents(V, adj);\n            System.out.println('Strongly Connected Components:');\n            for (List<Integer> scc : sccs) {\n                System.out.println(scc);\n            }\n        }\n    }\n\nTarjan's Algorithm in Java\n\nTarjan's Algorithm is a single-pass DFS algorithm that uses low-link values to identify SCCs.\n\nimport java.util.*;\n    \npublic class TarjanSCC {\n        private int time = 0;\n        private List<List<Integer>> sccs = new ArrayList<>();\n    \n        // Function to perform DFS and find SCCs using Tarjan's Algorithm\n        private void tarjanDFS(int v, int[] disc, int[] low, Deque<Integer> stack, boolean[] inStack, List<List<Integer>> adj) {\n            disc[v] = low[v] = ++time;\n            stack.push(v);\n            inStack[v] = true;\n    \n            for (int neighbor : adj.get(v)) {\n                if (disc[neighbor] == -1) {\n                    tarjanDFS(neighbor, disc, low, stack, inStack, adj);\n                    low[v] = Math.min(low[v], low[neighbor]);\n                } else if (inStack[neighbor]) {\n                    low[v] = Math.min(low[v], disc[neighbor]);\n                }\n            }\n    \n            if (low[v] == disc[v]) {\n                List<Integer> component = new ArrayList<>();\n                int w;\n                do {\n                    w = stack.pop();\n                    inStack[w] = false;\n                    component.add(w);\n                } while (w != v);\n                sccs.add(component);\n            }\n        }\n    \n        public List<List<Integer>> stronglyConnectedComponents(int V, List<List<Integer>> adj) {\n            int[] disc = new int[V];\n            int[] low = new int[V];\n            boolean[] inStack = new boolean[V];\n            Deque<Integer> stack = new ArrayDeque<>();\n    \n            Arrays.fill(disc, -1);\n            Arrays.fill(low, -1);\n    \n            for (int i = 0; i < V; i++) {\n                if (disc[i] == -1) {\n                    tarjanDFS(i, disc, low, stack, inStack, adj);\n                }\n            }\n            return sccs;\n        }\n    \n        public static void main(String[] args) {\n            TarjanSCC tarjan = new TarjanSCC();\n            int V = 5;\n            List<List<Integer>> adj = new ArrayList<>();\n            for (int i = 0; i < V; i++) {\n                adj.add(new ArrayList<>());\n            }\n    \n            adj.get(0).add(2);\n            adj.get(2).add(1);\n            adj.get(1).add(0);\n            adj.get(0).add(3);\n            adj.get(3).add(4);\n    \n            List<List<Integer>> sccs = tarjan.stronglyConnectedComponents(V, adj);\n            System.out.println('Strongly Connected Components:');\n            for (List<Integer> scc : sccs) {\n                System.out.println(scc);\n            }\n        }\n    }\n\nExplanation\n\nKosaraju's Algorithm:\n\nFirst DFS:\nTraverse the graph and push vertices onto a stack when finished (finishing time).\n\nTranspose Graph:\nReverse the direction of all edges.\n\nSecond DFS:\nPop vertices from the stack and perform DFS on the transposed graph. Each DFS tree gives one SCC.\n\nTarjan's Algorithm:\n\nDFS with Low-Link Values:\nPerform a single DFS traversal. Maintain discovery times and low-link values.\n\nUse a stack to keep track of the current path in the DFS tree.\n\nIf a node's low-link value equals its discovery time, it is the root of an SCC.\n\nComparing the Algorithms:\n\nKosaraju's Algorithm:\nSimpler to understand and implement.\nRequires two passes of the graph (two DFS traversals).\nUses an auxiliary stack to record finishing order.\n\nTarjan's Algorithm:\nMore efficient with a single pass of the graph.\nUses low-link values to identify SCCs.\nSlightly more complex due to the management of low-link values and the stack.\n\nBoth algorithms have a time complexity of O(V+E) and are efficient for large graphs. The choice depends on the specific problem constraints and personal preference for implementation complexity."
  ],
  "reservoir_sampling": [
    "Reservoir Sampling is a clever algorithm used for selecting a random sample of k items from an unknown or large stream of items, where the total number of items is not known in advance. It ensures that each item in the stream has an equal probability of being selected in the final sample.\n\nHere's a Python implementation of Reservoir Sampling for selecting k elements from a list:\n    \n    import random\n    \n    def reservoir_sampling(stream, k):\n        reservoir = []\n        \n        for i in range(k):\n            reservoir.append(stream[i])\n        \n       for i in range(k, len(stream)):\n           j = random.randint(0, i)\n            \n           if j < k:\n                reservoir[j] = stream[i]\n        \n        return reservoir\n    \n    stream = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n    k = 3\n    sample = reservoir_sampling(stream, k)\n    print('Random sample of size', k, ':', sample)\n\nIn this implementation, we maintain a reservoir of size k. We fill the reservoir with the first k elements from the stream. Then, for each subsequent element in the stream, we generate a random index between 0 and the current index. If the random index is less than k, we replace the element at that index in the reservoir with the current element from the stream. This way, each element in the stream has an equal probability of being included in the final sample.",
    "Rejection sampling is focused on generating samples from a specific distribution using a proposal distribution, while reservoir sampling is designed to handle the random selection of a fixed number of items from a potentially large and unknown-sized data stream."
  ],
  "line_sweep": [
    "A line sweep algorithm is a powerful computational geometry technique used to solve various problems efficiently by sweeping a line (or a plane in higher dimensions) across the plane to process geometric entities in a certain order. This technique is particularly useful for problems involving intersections, such as detecting if any two intervals overlap, finding the closest pair of points, or computing the union of rectangles.\n\nKey Concepts of Line Sweep:\n\nSweep Line: Imagine a line (usually vertical) sweeping across the plane from left to right (or bottom to top). As it moves, it processes events at specific positions.\n\nEvents: These are the points where the status of the sweep line changes. For example, in the case of interval overlap detection, events can be the starting and ending points of the intervals.\n\nEvent Queue: A priority queue that stores all events sorted by their position along the sweep direction. This ensures that events are processed in the correct order.\n\nStatus Structure: A data structure that maintains the current status of the sweep line, often implemented as a balanced binary search tree (BST). For example, in the case of interval overlap detection, the status structure could store the active intervals.\n\nExample Problems and Solutions:\n\n1. Interval Overlap Detection\n\nGiven a set of intervals, determine if any two intervals overlap.\n\nSteps:\n\nCreate events for all interval start and end points.\nSort the events based on their position.\nUse a status structure to keep track of active intervals.\nAs you process each event:\nIf it's a start event, check for overlaps with the active intervals.\nIf it's an end event, remove the corresponding interval from the status structure.\n\n2. Finding Closest Pair of Points\nGiven a set of points in the plane, find the pair with the smallest distance.\n\nSteps:\n\nSort points by their x-coordinates.\nSweep a vertical line across the points.\nUse a status structure (like a BST) to keep track of points in a vertical strip.\nFor each point, only consider points within a distance equal to the current smallest distance.\n\nExample: Interval Overlap Detection\n\nLet's illustrate this with a simple Python example for interval overlap detection.\n\nclass Event:\n    def __init__(self, x, is_start, interval):\n        self.x = x\n        self.is_start = is_start\n        self.interval = interval\n\ndef interval_overlap(intervals):\n    events = []\n    for interval in intervals:\n        events.append(Event(interval[0], True, interval))\n        events.append(Event(interval[1], False, interval))\n    \n    events.sort(key=lambda e: (e.x, not e.is_start))\n    \n    active_intervals = set()\n    for event in events:\n        if event.is_start:\n            for active in active_intervals:\n                if event.interval[0] < active[1]:\n                    return True\n            active_intervals.add(event.interval)\n        else:\n            active_intervals.remove(event.interval)\n    \n    return False\n\n# Example usage:\nintervals = [(1, 3), (2, 4), (5, 7)]\nprint(interval_overlap(intervals))  # Output: True\n\nIn this example, we create events for each interval's start and end points, sort them, and then use a set to maintain the currently active intervals. If we find an overlap, we return True; otherwise, we return False.\n\nLine sweep algorithms are versatile and can be adapted to many other computational geometry problems."
  ],
  "shell_sort": [
    "Shell sort is a classic sorting algorithm that is an improvement over insertion sort. It sorts elements at a gap, reducing the gap over time until it performs a final insertion sort at gap 1.",
    "Shell sort is an in-place comparison sort that is also known as Shell sort or Shell's method.",
    "It can be shown as a generalization of either exchange bubble sorting or insertion sorting.",
    "The method begins by sorting pairs of elements far apart from each other, then gradually narrows the gap between elements to be compared. ",
    "Some out-of-place elements can be moved into position faster than what a simple nearest-neighbor exchange would, by starting with far apart elements.",
    "This algorithm uses insertion sort on widely spread elements to sort them and then sort the less widely spaced elements. This spacing is termed as the interval. ",
    "Hereâ€™s how you can implement Shell sort:\n\ndef shellSort(arr):\n    n = len(arr)\n    gap = n // 2\n\n    # Start with a big gap, then reduce the gap\n    while gap > 0:\n        for i in range(gap, n):\n            temp = arr[i]\n\n            # Shift earlier gap-sorted elements up until the correct location for arr[i] is found\n            j = i\n            while j >= gap and arr[j - gap] > temp:\n                arr[j] = arr[j - gap]\n                j -= gap\n\n            # Put temp (the original arr[i]) in its correct location\n            arr[j] = temp\n\n        gap //= 2\n\narr = [12, 34, 54, 2, 3]\nshellSort(arr)\nprint('Sorted array is:', arr)\n\nThis implementation uses the Shell sort algorithm, which starts by comparing elements a certain gap apart and reduces the gap until it performs a final pass with gap 1. Here's a step-by-step explanation:\n\n1. Initialize the Gap: Start with a large gap and reduce it by half in each iteration.\n2. Sort Subarrays: For each gap size, sort the subarrays formed by taking every gap-th element.\n3. Insertion Sort: Use a modified insertion sort that operates over the gap-separated elements.\n4. Reduce the Gap: Continue reducing the gap and repeat the sorting process until the gap is 0.\n\nThis algorithm works well for medium-sized arrays and offers better performance than simple insertion sort due to its initial larger gap sizes, which help in moving elements closer to their final positions faster.",
    "Time Complexity\n\nThe time complexity of Shell sort is difficult to precisely determine due to its dependence on the chosen gap sequence. However, here are some general observations:\n\n1. Worst-case Time Complexity: \n   - For the original Shell's gap sequence (N/2, N/4, ..., 1), the worst-case time complexity is O(N^2).\n   - Using more efficient gap sequences, such as Hibbard's gaps (1, 3, 7, ..., 2^k - 1), the worst-case time complexity can be improved to O(N^{3/2}).\n   - Sedgewick's gaps can yield a worst-case time complexity of O(N^{4/3}).\n   - Using the best known gap sequence, the worst-case time complexity can be as good as O(N log^2 N).\n\n2. Average-case Time Complexity: \n   - With the original Shell's gap sequence, the average-case time complexity is around O(N^{5/4}).\n   - With more advanced gap sequences, the average-case time complexity is often closer to O(N log N).\n\n3. Best-case Time Complexity:\n   - The best-case time complexity is O(N log N), occurring when the input array is already nearly sorted, particularly with efficient gap sequences.\n\nSpace Complexity\n\nThe space complexity of Shell sort is straightforward:\n\n- Space Complexity: O(1)\n\nShell sort is an in-place sorting algorithm, meaning it requires a constant amount of additional space regardless of the input size.\n\nSummary\n\n- Worst-case Time Complexity: Ranges from O(N^2) (with simple gap sequences) to O(N log^2 N) (with advanced gap sequences).\n- Average-case Time Complexity: Generally closer to O(N log N) with efficient gap sequences.\n- Best-case Time Complexity: O(N log N).\n- Space Complexity: O(1) (in-place sorting).\n\nThe choice of gap sequence plays a crucial role in determining the efficiency of Shell sort, with more sophisticated sequences significantly improving its performance."
  ],
  "shell": [
    "Unix commands are essential tools for navigating, manipulating, and managing files and processes in a Unix-like operating system.\n\nThese problems require knowledge of Unix/Linux shell commands and scripting. :\n\nFile and Directory Management\n\n1. `ls`: Lists directory contents.\n   - `ls`: List files and directories in the current directory.\n   - `ls -l`: List in long format, showing file details.\n   - `ls -a`: List all files, including hidden files.\n\n2. `cd`: Changes the current directory.\n   - `cd /path/to/directory`: Change to specified directory.\n   - `cd ..`: Move up one directory level.\n   - `cd ~`: Change to the home directory.\n\n3. `pwd`: Prints the working directory.\n   - `pwd`: Displays the current directory path.\n\n4. `mkdir`: Creates a new directory.\n   - `mkdir new_directory`: Create a directory named `new_directory`.\n\n5. `rmdir`: Removes an empty directory.\n   - `rmdir directory`: Remove the specified empty directory.\n\n6. `rm`: Removes files or directories.\n   - `rm file`: Remove the specified file.\n   - `rm -r directory`: Remove the specified directory and its contents recursively.\n   - `rm -f file`: Force remove a file without prompting.\n\n7. `cp`: Copies files or directories.\n   - `cp source destination`: Copy file from source to destination.\n   - `cp -r source_directory destination`: Copy directory and its contents.\n\n8. `mv`: Moves or renames files or directories.\n   - `mv old_name new_name`: Rename a file or directory.\n   - `mv source destination`: Move file or directory to a new location.\n\n9. `ln`: Creates links between files.\n   - `ln source target`: Create a hard link.\n   - `ln -s source target`: Create a symbolic (soft) link.\n\nFile Content and Manipulation\n\n1. `cat`: Concatenates and displays file content.\n   - `cat file`: Display the content of a file.\n   - `cat file1 file2`: Concatenate and display multiple files.\n\n2. `more` and `less`: Views file content one screen at a time.\n   - `more file`: View file content with forward navigation.\n   - `less file`: View file content with forward and backward navigation.\n\n3. `head`: Outputs the first part of files.\n   - `head file`: Display the first 10 lines of a file by default.\n   - `head -n 5 file`: Display the first 5 lines of a file.\n\n4. `tail`: Outputs the last part of files.\n   - `tail file`: Display the last 10 lines of a file by default.\n   - `tail -n 5 file`: Display the last 5 lines of a file.\n\n5. `grep`: Searches for patterns within files.\n   - `grep 'pattern' file`: Search for a pattern in a file.\n   - `grep -r 'pattern' directory`: Recursively search for a pattern in a directory.\n\n6. `awk`: Pattern scanning and processing language.\n   - `awk '{print $1}' file`: Print the first column of each line.\n   - `awk '/pattern/ {print $0}' file`: Print lines matching the pattern.\n\n7. `sed`: Stream editor for filtering and transforming text.\n   - `sed 's/old/new/g' file`: Replace `old` with `new` globally in a file.\n   - `sed -n '10p' file`: Print the 10th line of a file.\n\n8. `tr`: Translates or deletes characters.\n   - `tr -s ' ' '\\n' < words.txt`: Translates spaces to newlines, effectively turning the file into a list of words.\n   - Common usage in conjunction with other commands for text processing.\n\nWord Frequency Count Example\n\nThis is a common task where you might want to count the frequency of each word in a text file:\n\nsh\ntr -s ' ' '\\n' < words.txt | sort | uniq -c | sort -nr\n\n\n- `tr -s ' ' '\\n' < words.txt`: Translates spaces into newlines, effectively turning the file into a list of words.\n- `sort`: Sorts the list of words.\n- `uniq -c`: Counts the occurrences of each unique word.\n- `sort -nr`: Sorts the counts in descending numerical order.\n\nFile Permissions and Ownership\n\n1. `chmod`: Changes file permissions.\n   - `chmod 755 file`: Set permissions to `rwxr-xr-x`.\n   - `chmod +x file`: Add execute permission.\n\n2. `chown`: Changes file owner and group.\n   - `chown user:group file`: Change the owner and group of a file.\n   - `chown user file`: Change only the owner of a file.\n\nProcess Management\n\n1. `ps`: Displays information about active processes.\n   - `ps`: Display current user's active processes.\n   - `ps aux`: Display detailed information about all processes.\n\n2. `top`: Displays real-time system summary and process list.\n   - `top`: Show real-time process information.\n\n3. `kill`: Terminates processes.\n   - `kill PID`: Send the default `TERM` signal to the process with `PID`.\n   - `kill -9 PID`: Forcefully terminate the process with `PID`.\n\n4. `bg` and `fg`: Manages background and foreground processes.\n   - `bg`: Resume a suspended job in the background.\n   - `fg`: Bring a background job to the foreground.\n\nNetworking\n\n1. `ping`: Checks network connectivity to a host.\n   - `ping hostname`: Send ICMP echo requests to the host.\n\n2. `ifconfig`: Configures network interfaces (deprecated, use `ip`).\n   - `ifconfig`: Display network interfaces and their statuses.\n\n3. `curl`: Transfers data from or to a server.\n   - `curl http://example.com`: Fetch content from a URL.\n\n4. `wget`: Retrieves files from the web.\n   - `wget http://example.com/file`: Download a file from a URL.\n\nDisk Usage\n\n1. `df`: Reports file system disk space usage.\n   - `df -h`: Display disk space usage in human-readable format.\n\n2. `du`: Estimates file space usage.\n   - `du -sh directory`: Display total size of a directory in human-readable format.\n\nArchiving and Compression\n\n1. `tar`: Archives files.\n   - `tar -cvf archive.tar directory`: Create a tar archive.\n   - `tar -xvf archive.tar`: Extract a tar archive.\n\n2. `gzip`: Compresses files.\n   - `gzip file`: Compress a file to `file.gz`.\n   - `gunzip file.gz`: Decompress a `.gz` file.\n\nConclusion\n\nThese Unix commands cover a broad range of tasks from file and directory management to process control, text processing, networking, and system monitoring. Mastering these commands can greatly enhance your efficiency and capability in managing Unix/Linux systems."
  ],
  "counting_sort": [
    "Counting Sort is a linear time sorting algorithm that sorts elements by counting the number of occurrences of each unique element in the input array. It's particularly useful when the range of input elements is known ahead of time and is not significantly larger than the number of elements to be sorted.\n\nHere's an implementation of Counting Sort:\n\ndef counting_sort(arr):\n    if len(arr) == 0:\n        return []\n\n    max_element = max(arr)\n\n    # Create a counting array to store the count of each element\n    count = [0] * (max_element + 1)\n\n    # Count the occurrences of each element in the input array\n    for num in arr:\n        count[num] += 1\n\n    # Reconstruct the sorted array using the counting array\n    sorted_arr = []\n    for i in range(len(count)):\n        sorted_arr.extend([i] * count[i])\n\n    return sorted_arr\n\nprint(counting_sort([2, 2, 3, 1]))\n\n[0, 1, 2, 1]\n\n[]\n[1]\n[2, 2]\n[3]\n[1, 2, 2, 3]\n \n\nThis implementation assumes that the input array `arr` consists of non-negative integers. It first finds the maximum element in the array to determine the size of the counting array. Then, it counts the occurrences of each element in the input array and reconstructs the sorted array based on the counts.\n\nCounting Sort has a time complexity of O(n + k), where n is the number of elements in the input array and k is the range of input values. It's not a comparison-based sorting algorithm, making it faster than comparison-based algorithms like Quick Sort or Merge Sort for certain types of input data, especially when the range of input values is small.\n\nFor LeetCode problems related to sorting algorithms, you can often adapt or directly use these implementations depending on the problem requirements and constraints.",
    "Time Complexity:\n\nCounting the occurrences of each element in the input array takes O(n) time, where n is the number of elements in the array.\nReconstructing the sorted array from the counting array takes O(n + k) time, where k is the range of input values.\nOverall, the time complexity is O(n + k).\nSpace Complexity:\n\nThe space complexity is dominated by the counting array, which requires O(k) additional space, where k is the range of input values.\nIn addition to the input array and the counting array, the algorithm uses a constant amount of extra space for variables and temporary arrays.\nThus, the space complexity is O(n + k).\nIn summary:\n\nTime Complexity: O(n + k)\nSpace Complexity: O(n + k)\nCounting Sort's space complexity can be problematic for large ranges of input values since it requires memory proportional to the range of input values. However, if the range is relatively small compared to the number of elements in the array (i.e., k is much smaller than n), Counting Sort can be an efficient sorting algorithm.\n"
  ],
  "minimum_spanning tree": [
    "A Minimum Spanning Tree (MST) of a weighted, connected, undirected graph is a spanning tree whose sum of edge weights is as small as possible. The spanning tree includes all the vertices of the graph, and the total weight of all the edges in the tree is minimized.",
    "Work In Progress..."
  ],
  "suffix_array": [
    "A suffix array is a powerful data structure used in string processing. It is an array of integers that represents the starting positions of the suffixes of a string, sorted in lexicographical order. \n\nKey Points\n\n1. Suffix: A suffix of a string is any substring that starts from a certain position and goes to the end of the string. For example, the suffixes of the string \"banana\" are \"banana\", \"anana\", \"nana\", \"ana\", \"na\", and \"a\".\n\n2. Suffix Array: The suffix array of a string is an array of the starting indices of the suffixes, sorted in lexicographical order of the suffixes themselves. \n\nExample\n\nConsider the string \"banana\":\n\n- Suffixes:\n  - \"banana\" (starting at index 0)\n  - \"anana\" (starting at index 1)\n  - \"nana\" (starting at index 2)\n  - \"ana\" (starting at index 3)\n  - \"na\" (starting at index 4)\n  - \"a\" (starting at index 5)\n\n- Sorted Suffixes:\n  - \"a\" (starting at index 5)\n  - \"ana\" (starting at index 3)\n  - \"anana\" (starting at index 1)\n  - \"banana\" (starting at index 0)\n  - \"na\" (starting at index 4)\n  - \"nana\" (starting at index 2)\n\n- Suffix Array:\n  - [5, 3, 1, 0, 4, 2]\n\nThe suffix array for \"banana\" is `[5, 3, 1, 0, 4, 2]`.\n\nProperties\n\n1. Efficiency: The suffix array can be constructed in (O(nlogn)) time using efficient algorithms.\n2. Space Complexity: It takes linear space relative to the size of the string.\n3. Applications: It is used in various applications such as substring search, pattern matching, data compression (like Burrows-Wheeler transform), and bioinformatics for DNA sequence analysis.\n\nConstruction of Suffix Array\n\nSteps\n\n1. Generate All Suffixes: Create all possible suffixes of the string.\n2. Sort Suffixes: Sort these suffixes lexicographically.\n3. Store Indices: Store the starting indices of these sorted suffixes in an array.\n\nJava Implementation\n\nHere's how you can implement a suffix array in Java:\n\nimport java.util.Arrays;\n\npublic class SuffixArray {\n\n    static class Suffix implements Comparable<Suffix> {\n        int index;\n        String suffix;\n\n        Suffix(int index, String suffix) {\n            this.index = index;\n            this.suffix = suffix;\n        }\n\n        @Override\n        public int compareTo(Suffix other) {\n            return this.suffix.compareTo(other.suffix);\n        }\n    }\n\n    public static int[] buildSuffixArray(String s) {\n        int n = s.length();\n        Suffix[] suffixes = new Suffix[n];\n\n        for (int i = 0; i < n; i++) {\n            suffixes[i] = new Suffix(i, s.substring(i));\n        }\n\n        // Step 2: Sort the suffixes lexicographically\n        Arrays.sort(suffixes);\n\n        int[] suffixArray = new int[n];\n        for (int i = 0; i < n; i++) {\n            suffixArray[i] = suffixes[i].index;\n        }\n\n        return suffixArray;\n    }\n\n    public static void main(String[] args) {\n        String s = \"banana\";\n        int[] suffixArray = buildSuffixArray(s);\n        System.out.println(\"Suffix array: \" + Arrays.toString(suffixArray));\n    }\n}\n\nExplanation of the Code\n\n- Suffix Class:\n  - Holds each suffix and its starting index.\n  - Implements `Comparable` to enable sorting based on the suffix string.\n\n- buildSuffixArray Function:\n  - Step 1: Generate all suffixes by iterating through each character in the string.\n  - Step 2: Sort the suffixes lexicographically using Javaâ€™s `Arrays.sort` function.\n  - Step 3: Extract and store the starting indices of the sorted suffixes.\n\nConclusion\n\nThe suffix array is an efficient and versatile data structure for string processing tasks. It provides a compact way to index all suffixes of a string, enabling fast search and analysis operations.",
    "Time Complexity\n\n1. Naive Approach:\n    - Generating all suffixes: (O(n^2))\n    - Sorting suffixes: (O(n^2 log n))\n    - Total Time Complexity: (O(n^2 log n))\n\n2. Efficient Algorithms:\n    - Manber and Myers Algorithm: (O(n log n))\n    - KÃ¤rkkÃ¤inen-Sanders Algorithm: (O(n))\n    - Total Time Complexity: (O(n log n)) or (O(n))\n\nSpace Complexity\n\n1. Naive Approach:\n    - Storing all suffixes: (O(n^2))\n    - Suffix Array: (O(n))\n    - Total Space Complexity: (O(n^2))\n\n2. Efficient Algorithms:\n    - Storing suffix array and auxiliary arrays: (O(n))\n    - Total Space Complexity: (O(n))\n\nSummary\n\n- Naive Approach:\n    - Time Complexity: (O(n^2 log n))\n    - Space Complexity: (O(n^2))\n\n- Efficient Algorithms:\n    - Time Complexity: (O(n log n)) or (O(n))\n    - Space Complexity: (O(n))\n\nEfficient algorithms significantly improve performance, making them more practical for large inputs. The naive approach is easier to understand but less practical for large strings due to higher time and space complexities.",
    "To construct the LCP (Longest Common Prefix) array using the suffix array, we need to follow a systematic approach after building the suffix array itself. Hereâ€™s how we can do it:\n\nSteps to Build LCP Array Using Suffix Array\n\n1. Sort Suffixes:\n   - First, generate the suffixes from the string `s`, each suffix represented by its starting index.\n   - Sort these suffixes lexicographically. This sorting step establishes the order of suffixes based on their starting characters.\n\n2. Build Suffix Array:\n   - From the sorted suffixes, create a suffix array that holds the indices of the sorted suffixes.\n\n3. Compute Rank Array:\n   - Construct a rank array where `rank[i]` gives the position of the suffix starting at index `i` in the sorted order of suffixes.\n\n4. Compute LCP Array:\n   - Initialize an array `lcp` of length `n-1`, where `n` is the length of the string `s`.\n   - Iterate through the suffix array to compute the LCP values between consecutive suffixes in the sorted order.\n   - Use the rank array to efficiently compare consecutive suffixes and determine their common prefix length.\n\nExample Implementation\n\nHereâ€™s a Java implementation that builds the suffix array and computes the LCP array:\n\njava\nimport java.util.*;\n\npublic class Solution {\n\n    public static void main(String[] args) {\n        String s = \"banana\";\n        int[] sa = buildSuffixArray(s);\n        int[] lcp = buildLCPArray(s, sa);\n        System.out.println(\"Suffix Array: \" + Arrays.toString(sa));\n        System.out.println(\"LCP Array: \" + Arrays.toString(lcp));\n    }\n\n    public static int[] buildSuffixArray(String s) {\n        int n = s.length();\n        Suffix[] suffixes = new Suffix[n];\n\n        for (int i = 0; i < n; i++) {\n            suffixes[i] = new Suffix(i, s.substring(i));\n        }\n\n        Arrays.sort(suffixes);\n\n        int[] suffixArray = new int[n];\n        for (int i = 0; i < n; i++) {\n            suffixArray[i] = suffixes[i].index;\n        }\n\n        return suffixArray;\n    }\n\n    public static int[] buildLCPArray(String s, int[] suffixArray) {\n        int n = s.length();\n        int[] rank = new int[n];\n        int[] lcp = new int[n - 1];\n\n        for (int i = 0; i < n; i++) {\n            rank[suffixArray[i]] = i;\n        }\n\n        int h = 0;\n        for (int i = 0; i < n; i++) {\n            if (rank[i] > 0) {\n                int j = suffixArray[rank[i] - 1];\n                while (i + h < n && j + h < n && s.charAt(i + h) == s.charAt(j + h)) {\n                    h++;\n                }\n                lcp[rank[i] - 1] = h;\n                if (h > 0) {\n                    h--;\n                }\n            }\n        }\n\n        return lcp;\n    }\n\n    static class Suffix implements Comparable<Suffix> {\n        int index;\n        String suffix;\n\n        Suffix(int index, String suffix) {\n            this.index = index;\n            this.suffix = suffix;\n        }\n\n        @Override\n        public int compareTo(Suffix other) {\n            return this.suffix.compareTo(other.suffix);\n        }\n    }\n}\n\n\nExplanation\n\n- Suffix Array Construction:\n  - `buildSuffixArray(String s)` method constructs an array of suffixes sorted lexicographically and then builds a suffix array using the indices of these sorted suffixes.\n\n- LCP Array Construction:\n  - `buildLCPArray(String s, int[] suffixArray)` method computes the LCP array using the constructed suffix array and the rank of suffixes.\n  - It iterates through the suffix array, comparing consecutive suffixes based on their ranks to determine the length of their common prefix.\n\n- Rank Array Usage:\n  - `rank` array is crucial in `buildLCPArray` to quickly find the position of each suffix in the sorted order and thus efficiently compute LCP values.\n\nThis approach ensures efficient computation of the LCP array using the suffix array, making it suitable for applications like finding the longest common prefix among all suffixes of a string efficiently."
  ],
  "bucket_sort": [
    "Bucket sort is a sorting algorithm that works well when the input is uniformly distributed over a range. It divides the input array into a number of buckets, each of which is then sorted individually, typically with another sorting algorithm or by recursively applying bucket sort itself if necessary. After sorting each bucket, the sorted buckets are concatenated to obtain the sorted array.\n\nHere's a step-by-step breakdown of how bucket sort typically works:\n\n1. Divide into Buckets: Create an array of buckets, where each bucket is responsible for a subrange of the input elements.\n\n2. Distribution: Iterate through the input array, placing each element into its corresponding bucket based on some function that maps elements to buckets. This function should distribute elements uniformly across the buckets.\n\n3. Sort Buckets: Sort each individual bucket. This can be done using any suitable sorting algorithm, such as insertion sort, quicksort, or recursively applying bucket sort itself.\n\n4. Concatenate Buckets: Concatenate all sorted buckets to get the sorted array.\n\nimport java.util.ArrayList;\nimport java.util.Collections;\nimport java.util.List;\n\npublic class BucketSort {\n\n    public static void bucketSort(float[] arr) {\n        int n = arr.length;\n\n        List<Float>[] buckets = new ArrayList[n];\n        for (int i = 0; i < n; i++) {\n            buckets[i] = new ArrayList<>();\n        }\n\n        for (int i = 0; i < n; i++) {\n            int bucketIndex = (int) (arr[i] * n);\n            buckets[bucketIndex].add(arr[i]);\n        }\n\n        for (int i = 0; i < n; i++) {\n            Collections.sort(buckets[i]); \n        }\n\n        int index = 0;\n        for (int i = 0; i < n; i++) {\n            for (float num : buckets[i]) {\n                arr[index++] = num;\n            }\n        }\n    }\n\n    public static void main(String[] args) {\n        float[] arr = {0.42f, 0.32f, 0.88f, 0.23f, 0.65f, 0.11f, 0.55f};\n\n        System.out.println(\"Array before sorting:\");\n        printArray(arr);\n\n        bucketSort(arr);\n\n        System.out.println(\"Array after sorting:\");\n        printArray(arr);\n    }\n\n    public static void printArray(float[] arr) {\n        for (float num : arr) {\n            System.out.print(num + ",
    ");\n        }\n        System.out.println();\n    }\n}\n\nExplanation:\n\n1. Initialization: \n   - `bucketSort(float[] arr)`: This method accepts an array of floats and performs bucket sort on it.\n   - `buckets` array is initialized as an array of `ArrayList<Float>`, where each index corresponds to a bucket.\n\n2. Distribution:\n   - Each element in the input array `arr` is placed into its respective bucket. The bucket index is determined by multiplying the element by `n` (number of elements) and taking the integer part.\n\n3. Sorting:\n   - Each bucket is sorted individually. In this implementation, `Collections.sort()` is used for simplicity. Other sorting algorithms like insertion sort or quicksort could be used depending on the specific requirements or characteristics of the data.\n\n4. Concatenation:\n   - Finally, the sorted elements from each bucket are concatenated back into the original array `arr`.\n\n5. Main Method:\n   - `main(String[] args)`: Example usage demonstrating how to use `bucketSort` method on a sample array of floats.\n   - `printArray(float[] arr)`: Utility method to print the contents of an array.\n\nNotes:\n- This implementation assumes sorting floating-point numbers between 0 and 1. For sorting integers or other ranges, adjustments to the bucket index calculation and handling of elements may be necessary.\n- The choice of sorting algorithm within each bucket (`Collections.sort()` in this case) can be tailored based on performance requirements and characteristics of the data.\n- Bucket sort's performance can be influenced by the number of buckets chosen (`n` in this implementation) and the distribution of input data. Adjusting these parameters can optimize the algorithm for specific use cases.\n\nTime Complexity\n\n- Best Case: If the elements are uniformly distributed across buckets and each bucket is efficiently sorted, the time complexity can be close to ( O(n) ), where ( n ) is the number of elements.\n  \n- Average Case: In the average case, bucket sort typically runs in ( O(n + k) ), where ( n ) is the number of elements to be sorted and ( k ) is the number of buckets. Sorting each bucket takes ( O(n_i log n_i) ) on average, where ( n_i ) is the number of elements in bucket ( i ).\n  \n- Worst Case: In the worst case, when all elements are placed in a single bucket, it can degrade to ( O(n^2) ) due to the time required to sort each bucket individually.\n\nSpace Complexity\n\n- Bucket sort requires additional space to store the buckets, making its space complexity ( O(n + k) ), where ( n ) is the number of elements and ( k ) is the number of buckets. This space is needed to hold the elements in each bucket before they are concatenated back into the sorted array.\n\nCertainly! Here's a simple Java implementation of bucket sort. In this example, I'll assume we're sorting an array of floating-point numbers between 0 and 1, but bucket sort can be adapted to sort integers or other data types as well.\n\n\nSummary\n\nBucket sort is effective for sorting elements uniformly distributed across a range and can perform well when the number of buckets is appropriately chosen relative to the number of elements. However, its performance can degrade if the distribution of elements is skewed or if there are too few buckets relative to the number of elements.\n\nOverall, bucket sort is a useful algorithm in scenarios where the input data is distributed evenly and the range of possible values is known and relatively small compared to the number of elements being sorted."
  ],
  "quickselect": [
    "Quickselect is an efficient algorithm for finding the k-th smallest (or largest) element in an unordered list. It works similarly to the quicksort algorithm by partitioning the array. Here's a common problem from Leetcode that can be solved using Quickselect:\n\nProblem: Kth Largest Element in an Array\n\nDescription:\nFind the k-th largest element in an unsorted array. Note that it is the k-th largest element in sorted order, not the k-th distinct element.\n\nExample 1:\nInput: [3,2,1,5,6,4] and k = 2\nOutput: 5\n\n\nExample 2:\nInput: [3,2,3,1,2,4,5,5,6] and k = 4\nOutput: 4\n\n\nNote:\nYou may assume k is always valid, 1 â‰¤ k â‰¤ array's length.\n\nSolution using Quickselect\n\npython\nimport random\n\nclass Solution:\n    def findKthLargest(self, nums: List[int], k: int) -> int:\n        def partition(left, right, pivot_index):\n            pivot = nums[pivot_index]\n            nums[pivot_index], nums[right] = nums[right], nums[pivot_index]\n            store_index = left\n            # Move all smaller elements to the left\n            for i in range(left, right):\n                if nums[i] < pivot:\n                    nums[store_index], nums[i] = nums[i], nums[store_index]\n                    store_index += 1\n            nums[right], nums[store_index] = nums[store_index], nums[right]\n            return store_index\n        \n        def quickselect(left, right, k_smallest):\n            if left == right:\n                return nums[left]\n            \n            pivot_index = random.randint(left, right)\n            \n            # Find the pivot position in a sorted list\n            pivot_index = partition(left, right, pivot_index)\n            \n            # The pivot is in its final sorted position\n            if k_smallest == pivot_index:\n                return nums[k_smallest]\n            elif k_smallest < pivot_index:\n                return quickselect(left, pivot_index - 1, k_smallest)\n            else:\n                return quickselect(pivot_index + 1, right, k_smallest)\n        \n        # kth largest is the (n - k)th smallest\n        return quickselect(0, len(nums) - 1, len(nums) - k)\n\n\nExplanation\n\n1. Partitioning:\n   - Similar to quicksort, the partition function rearranges the elements so that elements less than the pivot are on the left, elements greater than the pivot are on the right, and the pivot is in its final position.\n   \n2. Quickselect:\n   - This function recursively selects the k-th smallest element (which translates to the (n - k)-th smallest when finding the k-th largest element).\n   - It selects a random pivot and partitions the array.\n   - Depending on the pivot's position, it recursively searches in the left or right partition.\n\n3. Conversion:\n   - Since we need the k-th largest, we convert it to finding the (n - k)-th smallest element.\n\nKey Points\n\n- Time Complexity: Average O(n), Worst O(n^2)\n- Space Complexity: O(1) (in-place)\n\nUsing the median of medians ensures that the worst-case time complexity remains O(n), making it more robust for cases where consistent performance is critical.\n\nThis method is efficient for problems requiring the k-th largest or smallest element in an unsorted list and leverages the partitioning logic of quicksort to achieve optimal performance on average."
  ],
  "probability_and_statistics":[
    "Probability and Statistics problem solving involves applying mathematical principles to analyze data and predict outcomes based on probability distributions. Here are a few key concepts and example problems that demonstrate how these principles are applied\n\nKey Concepts in Probability and Statistics\n\n1. Probability Basics:\n   - Probability of Events: Calculating the likelihood of an event occurring based on the total number of possible outcomes.\n   - Conditional Probability: Probability of an event given that another event has occurred.\n   - Bayes Theorem: Relates the conditional and marginal probabilities of two random events.\n\n2. Random Variables and Distributions:\n   - Discrete and Continuous Variables: Variables that can take on distinct values vs. those that can take on any value within a range.\n   - Probability Distributions: Describes the likelihood of different outcomes in a population.\n     - Binomial Distribution: Probability distribution of the number of successes in a fixed number of independent Bernoulli trials.\n     - Normal Distribution: Bell-shaped distribution that is symmetric around the mean.\n     - Poisson Distribution: Describes the number of events occurring in a fixed interval of time or space.\n   \n3. Statistical Measures:\n   - Mean, Median, Mode: Measures of central tendency.\n   - Variance and Standard Deviation: Measures of dispersion or spread of data points around the mean.\n\n4. Hypothesis Testing and Confidence Intervals:\n   - Hypothesis Testing: Assessing the validity of a hypothesis using statistical analysis.\n   - Confidence Intervals: Range of values within which a population parameter is estimated to lie.\n\nExample Problems\n\nHere are some example problems that illustrate different aspects of Probability and Statistics:\n\n1. Probability Problem:\n   - Calculate the probability of drawing a certain color from a bag of colored balls, given the total number of each color.\n   - Example: What is the probability of drawing a red ball from a bag containing 3 red, 2 blue, and 5 green balls?\n\n2. Distribution Problem:\n   - Determine the mean and standard deviation of a set of exam scores.\n   - Example: Given exam scores of 80, 85, 90, 75, and 95, calculate the mean and standard deviation.\n\n3. Hypothesis Testing Problem:\n   - Test whether the mean weight of apples produced by two different farms is significantly different.\n   - Example: Farm A claims their apples weigh, on average, 150 grams, while Farm B claims their apples weigh, on average, 160 grams. Test whether there is a significant difference in their average weights.\n\n4. Bayesian Inference Problem:\n   - Use Bayes theorem to update beliefs based on new evidence.\n   - Example: Given the results of a medical test, calculate the probability that a person has a disease, knowing the sensitivity and specificity of the test.\n\n5. Regression Problem:\n   - Predict the price of a house based on its size, location, and other factors using linear regression.\n   - Example: Develop a model to predict the selling price of houses based on features like square footage, number of bedrooms, and neighborhood.\n\nProblem-Solving Approach\n\nWhen approaching Probability and Statistics problems, it's essential to:\n- Understand the Problem Statement: Clearly define what needs to be calculated or inferred.\n- Choose the Right Approach: Select appropriate formulas, distributions, or statistical tests based on the problem requirements.\n- Calculate and Interpret Results: Perform calculations accurately and interpret the results in the context of the problem.\n- Validate and Test: Verify calculations and test assumptions to ensure accuracy and reliability of results."
  ]
}